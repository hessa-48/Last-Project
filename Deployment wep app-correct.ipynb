{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a7e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.21.0)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\huawei\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.2-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.4 MB 2.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.3/10.4 MB 3.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.1/10.4 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.1/10.4 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.9/10.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.0/10.4 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.5/10.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.0/10.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.6/10.4 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.3/10.4 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.9/10.4 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.0/10.4 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Installing collected packages: safetensors, huggingface-hub, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.29.2\n",
      "    Uninstalling huggingface-hub-0.29.2:\n",
      "      Successfully uninstalled huggingface-hub-0.29.2\n",
      "Successfully installed huggingface-hub-0.30.2 safetensors-0.5.3 transformers-4.51.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "pip install openai\n",
    "pip install nltk\n",
    "pip install scikit-learn\n",
    "pip install scikit-learn\n",
    "pip install gradio\n",
    "!pip install pyarrow\n",
    "pip install sentence-transformers\n",
    "pip install protobuf\n",
    "!pip install torch --pre --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b45dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = \"C:/Users/Huawei/Desktop/classification model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ee67b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "RobertaTokenizerFast(name_or_path='C:/Users/Huawei/Desktop/classification model', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"C:/Users/Huawei/Desktop/classification model\"  # Update this path if necessary\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Print the model and tokenizer to verify everything is loaded\n",
    "print(model)\n",
    "print(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52cb175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully 🎉\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"C:/Users/Huawei/Desktop/classification model\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Move model to device (CPU or CUDA if available)\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully 🎉\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4c39545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import joblib\n",
    "\n",
    "# Load the embeddings (assuming it's a NumPy array)\n",
    "embeddings = np.load(r\"C:\\Users\\Huawei\\Desktop\\clustring model\\embeddings.npy\")\n",
    "\n",
    "# Load the pre-trained KMeans model\n",
    "kmeans_model = joblib.load(r\"C:\\Users\\Huawei\\Desktop\\clustring model\\kmeans_model.pkl\")\n",
    "\n",
    "# Load the reviews if you plan to use them\n",
    "reviews = pd.read_parquet(r\"C:\\Users\\Huawei\\Desktop\\clustring model\\reviews_processed.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830cf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Huawei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Huawei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the final projectt\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from openai import OpenAI\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Setup\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# GPT-4 setup (keep your actual key here)\n",
    "client = OpenAI(api_key=\"my key\")\n",
    "\n",
    "# Classification pipeline\n",
    "model_path = \"C:/Users/Huawei/Desktop/classification model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# Category clusters\n",
    "cluster_mapping = {\n",
    "    0: \"Online offers\",\n",
    "    1: \"electronics\",\n",
    "    2: \"For Kids\",\n",
    "    3: \"E-Readers & Home\",\n",
    "    4: \"best purchase\",\n",
    "    5: \"Voice-Enabled Tab\"\n",
    "}\n",
    "\n",
    "# Summarization helper functions\n",
    "def convert_df_to_json(df, selected_category):\n",
    "    grouped_data = defaultdict(lambda: {\"reviews\": [], \"category\": \"\"})\n",
    "    for _, row in df.iterrows():\n",
    "        if str(row.get('category')) != selected_category:\n",
    "            continue\n",
    "        product = row.get('name')\n",
    "        review_text = row.get('reviews.text')\n",
    "        rating = row.get('reviews.rating')\n",
    "        if pd.notnull(review_text) and pd.notnull(rating):\n",
    "            grouped_data[product][\"reviews\"].append({\n",
    "                \"text\": str(review_text),\n",
    "                \"rating\": float(rating)\n",
    "            })\n",
    "            grouped_data[product][\"category\"] = selected_category\n",
    "\n",
    "    structured_reviews = []\n",
    "    for product, details in grouped_data.items():\n",
    "        if len(details[\"reviews\"]) >= 2:\n",
    "            ratings = [r[\"rating\"] for r in details[\"reviews\"]]\n",
    "            texts = [r[\"text\"] for r in details[\"reviews\"]]\n",
    "            structured_reviews.append({\n",
    "                \"product_name\": product,\n",
    "                \"category\": details[\"category\"],\n",
    "                \"avg_rating\": sum(ratings) / len(ratings),\n",
    "                \"top_pros\": [t for t in texts if \"good\" in t.lower() or \"great\" in t.lower()][:2],\n",
    "                \"top_complaints\": [t for t in texts if \"bad\" in t.lower() or \"disappoint\" in t.lower()][:2]\n",
    "            })\n",
    "    return structured_reviews\n",
    "\n",
    "def build_insight_string(products):\n",
    "    sorted_products = sorted(products, key=lambda x: x[\"avg_rating\"], reverse=True)\n",
    "    top_3 = sorted_products[:3]\n",
    "    worst = sorted_products[-1]\n",
    "\n",
    "    insights_str = \"\"\n",
    "    for idx, p in enumerate(top_3, 1):\n",
    "        insights_str += f\"\"\"{idx}. {p['product_name']} - Rating: {p['avg_rating']:.2f}\n",
    "Key Pros: {\", \".join(p['top_pros']) or \"N/A\"}\n",
    "Top Complaints: {\", \".join(p['top_complaints']) or \"N/A\"}\\n\\n\"\"\"\n",
    "\n",
    "    insights_str += f\"Worst Product:\\n{worst['product_name']} - Rating: {worst['avg_rating']:.2f}\\n\"\n",
    "    insights_str += f\"Complaints: {', '.join(worst['top_complaints']) or 'N/A'}\"\n",
    "    return insights_str\n",
    "\n",
    "def generate_article(category, insights):\n",
    "    prompt = f\"\"\"\n",
    "You are a professional tech writer.\n",
    "\n",
    "Write a clear, structured summary about the product category: \"{category}\".\n",
    "\n",
    "The summary should include:\n",
    "1. Top 3 products in this category and their key differences.\n",
    "2. Top complaints for each of those top 3 products.\n",
    "3. The worst product and why users should avoid it.\n",
    "\n",
    "Here are the insights to use:\n",
    "{insights}\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=900\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Classification logic\n",
    "def classify_text(text):\n",
    "    result = classifier(text)\n",
    "    label = result[0]['label']\n",
    "    return {\"LABEL_0\": \"Negative\", \"LABEL_1\": \"Neutral\", \"LABEL_2\": \"Positive\"}.get(label, \"Unknown\")\n",
    "\n",
    "# Summary generation logic\n",
    "def handle_summary(file, category):\n",
    "    if not file:\n",
    "        return \"Please upload a file.\"\n",
    "    if not category:\n",
    "        return \"Please select a category.\"\n",
    "    try:\n",
    "        df = pd.read_csv(file.name)\n",
    "        df.rename(columns={\"categories\": \"category\"}, inplace=True)  # ✅ FIXED COLUMN NAME\n",
    "        insights = convert_df_to_json(df, category)\n",
    "        if not insights:\n",
    "            return f\"No sufficient reviews for the selected category: {category}\"\n",
    "        insight_str = build_insight_string(insights)\n",
    "        return generate_article(category, insight_str)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🤖 الحاكم\")\n",
    "\n",
    "    with gr.Tab(\"🔍 Classification\"):\n",
    "        txt = gr.Textbox(label=\"Enter text to classify\")\n",
    "        out = gr.Label()\n",
    "        classify_btn = gr.Button(\"Classify\")\n",
    "        classify_btn.click(classify_text, txt, out)\n",
    "\n",
    "    with gr.Tab(\"📚 Category Summary\"):\n",
    "        gr.Markdown(\"### Step 1: Select a Category\")\n",
    "        selected_category = gr.Radio(choices=list(cluster_mapping.values()), label=\"Select Category\")\n",
    "\n",
    "        gr.Markdown(\"### Step 2: Upload Your CSV\")\n",
    "        file_input = gr.File(label=\"Upload CSV\", file_types=[\".csv\"])\n",
    "        generate_btn = gr.Button(\"Generate Summary\")\n",
    "        summary_output = gr.Textbox(label=\"Generated Summary\", lines=25)\n",
    "\n",
    "        generate_btn.click(fn=handle_summary, inputs=[file_input, selected_category], outputs=summary_output)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66e7003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Huawei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Huawei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cluster_btn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 150\u001b[39m\n\u001b[32m    147\u001b[39m         clusters = cluster_texts(lines, n)\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m clusters.items()])\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[43mcluster_btn\u001b[49m.click(cluster_handler, [cluster_input, cluster_num], cluster_output)\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m gr.Tab(\u001b[33m\"\u001b[39m\u001b[33m📚 GPT-4 Review Summarizer\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    153\u001b[39m     gr.Markdown(\u001b[33m\"\u001b[39m\u001b[33mUpload your review dataset and select a cluster category.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'cluster_btn' is not defined"
     ]
    }
   ],
   "source": [
    "# Paste this into your Python environment\n",
    "\n",
    "import gradio as gr\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# NLTK Downloads\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# --- Load Local Models ---\n",
    "summ_model = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "\n",
    "model_path = \"C:/Users/Huawei/Desktop/classification model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "classifier_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "classifier = pipeline(\"text-classification\", model=classifier_model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# --- Sentence Embedding & Clustering ---\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "kmeans_model = joblib.load(\"C:/Users/Huawei/Desktop/clustring model/kmeans_model.pkl\")\n",
    "embeddings = np.load(\"C:/Users/Huawei/Desktop/clustring model/embeddings.npy\")\n",
    "\n",
    "# --- GPT Client ---\n",
    "client = OpenAIapi_key=(\"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\")  # Replace with your OpenAI key\n",
    "# --- Load Reviews ---\n",
    "df = pd.read_csv(\"C:/Users/Huawei/Desktop/cr/clustered_reviews.csv\")  # Assuming CSV is your final format\n",
    "\n",
    "# --- Cluster Labels ---\n",
    "cluster_labels = sorted(df[\"merged_cluster\"].dropna().unique().tolist())\n",
    "\n",
    "# --- CLASSIFICATION ---\n",
    "def classify_text(text):\n",
    "    result = classifier(text)\n",
    "    label = result[0]['label']\n",
    "    label_mapping = {\n",
    "        \"LABEL_0\": \"Negative\",\n",
    "        \"LABEL_1\": \"Neutral\",\n",
    "        \"LABEL_2\": \"Positive\"\n",
    "    }\n",
    "    return label_mapping.get(label, \"Unknown\")\n",
    "\n",
    "# --- CLUSTERING ---\n",
    "def cluster_texts(texts, n_clusters):\n",
    "    embeddings = embedding_model.encode(texts)\n",
    "    cluster_labels = kmeans_model.predict(embeddings)\n",
    "    clusters = {f\"Cluster {i}\": [] for i in range(n_clusters)}\n",
    "    for idx, label in enumerate(cluster_labels):\n",
    "        clusters[f\"Cluster {label}\"].append(texts[idx])\n",
    "    return clusters\n",
    "\n",
    "# --- SUMMARIZATION ---\n",
    "def summarize_text(text):\n",
    "    summary = summ_model(text, max_length=130, min_length=30, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# --- GPT-4 CLUSTER-BASED REVIEW SUMMARIZER ---\n",
    "def generate_summary_from_cluster(cluster_label, file):\n",
    "    try:\n",
    "        # Load from file if uploaded, else use default df\n",
    "        if file is not None:\n",
    "            if file.name.endswith(\".csv\"):\n",
    "                user_df = pd.read_csv(file.name)\n",
    "            elif file.name.endswith(\".parquet\"):\n",
    "                user_df = pd.read_parquet(file.name)\n",
    "            else:\n",
    "                return \"❌ Unsupported file type. Please upload a CSV or Parquet file.\"\n",
    "\n",
    "            if 'reviews.text' not in user_df.columns or 'merged_cluster' not in user_df.columns:\n",
    "                return \"❌ Uploaded file must contain 'reviews.text' and 'merged_cluster' columns.\"\n",
    "        else:\n",
    "            user_df = df\n",
    "\n",
    "        if cluster_label not in user_df[\"merged_cluster\"].unique():\n",
    "            return \"⚠️ Selected cluster label not found in the dataset.\"\n",
    "\n",
    "        reviews = user_df[user_df[\"merged_cluster\"] == cluster_label][\"reviews.text\"].dropna().tolist()\n",
    "\n",
    "        if len(reviews) == 0:\n",
    "            return \"⚠️ No reviews found for the selected cluster.\"\n",
    "\n",
    "        reviews = reviews[:100]  # Limit to 100 reviews for prompt\n",
    "        formatted_reviews = \"\\n\".join(f\"- {r}\" for r in reviews)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are a product review analyst.\n",
    "\n",
    "Here are customer reviews for a product category: \"{cluster_label}\".\n",
    "\n",
    "---\n",
    "\n",
    "{formatted_reviews}\n",
    "\n",
    "---\n",
    "\n",
    "Please generate a structured article-style summary with:\n",
    "\n",
    "1. Top 3 products in this category and their key differences.\n",
    "2. Top complaints for each of those top 3 products.\n",
    "3. The worst product and why users should avoid it.\n",
    "\n",
    "Make it insightful and clear.\n",
    "\"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful product review summarizer.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"❌ An error occurred while processing: {e}\"\n",
    "\n",
    "# --- GRADIO UI ---\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🤖 **الحاكم**\")\n",
    "\n",
    "    with gr.Tab(\"🔍 Classification\"):\n",
    "        txt_input = gr.Textbox(label=\"Enter text to classify\")\n",
    "        txt_output = gr.Label()\n",
    "        classify_btn = gr.Button(\"Classify\")\n",
    "        classify_btn.click(classify_text, txt_input, txt_output)\n",
    "\n",
    "    \n",
    "\n",
    "        def cluster_handler(texts, n):\n",
    "            lines = texts.strip().split(\"\\n\")\n",
    "            clusters = cluster_texts(lines, n)\n",
    "            return \"\\n\\n\".join([f\"{key}:\\n\" + \"\\n\".join(value) for key, value in clusters.items()])\n",
    "\n",
    "        cluster_btn.click(cluster_handler, [cluster_input, cluster_num], cluster_output)\n",
    "\n",
    "    with gr.Tab(\"📚 GPT-4 Review Summarizer\"):\n",
    "        gr.Markdown(\"Upload your review dataset and select a cluster category.\")\n",
    "        category_dropdown = gr.Dropdown(choices=cluster_labels, label=\"Select Cluster Category\")\n",
    "        file_upload = gr.File(label=\"Upload your review file (.csv or .parquet)\", file_types=[\".csv\", \".parquet\"])\n",
    "        summary_output = gr.Textbox(label=\"Generated Summary\", lines=20)\n",
    "        summarize_btn = gr.Button(\"Generate Summary\")\n",
    "        summarize_btn.click(generate_summary_from_cluster, [category_dropdown, file_upload], summary_output)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b61299fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Huawei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Huawei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\blocks.py\", line 2137, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\blocks.py\", line 1663, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\utils.py\", line 890, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_25456\\2451833931.py\", line 139, in <lambda>\n",
      "    gr.Button(cluster_name).click(lambda c=cluster_name: gr.Textbox.update(value=c), outputs=selected_category)\n",
      "                                                         ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: type object 'Textbox' has no attribute 'update'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\blocks.py\", line 2137, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\blocks.py\", line 1663, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\utils.py\", line 890, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_25456\\2451833931.py\", line 139, in <lambda>\n",
      "    gr.Button(cluster_name).click(lambda c=cluster_name: gr.Textbox.update(value=c), outputs=selected_category)\n",
      "                                                         ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: type object 'Textbox' has no attribute 'update'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\blocks.py\", line 2137, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\blocks.py\", line 1663, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\Huawei\\Desktop\\deploymentt\\myenv\\Lib\\site-packages\\gradio\\utils.py\", line 890, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_25456\\2451833931.py\", line 139, in <lambda>\n",
      "    gr.Button(cluster_name).click(lambda c=cluster_name: gr.Textbox.update(value=c), outputs=selected_category)\n",
      "                                                         ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: type object 'Textbox' has no attribute 'update'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "\n",
    "# NLTK setup\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Device\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Summarization model\n",
    "summ_model = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "\n",
    "# Classification model\n",
    "model_path = \"C:/Users/Huawei/Desktop/classification model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "classifier_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "classifier = pipeline(\"text-classification\", model=classifier_model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# Embedding and clustering\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "kmeans_model = joblib.load(\"C:/Users/Huawei/Desktop/clustring model/kmeans_model.pkl\")\n",
    "\n",
    "# OpenAI GPT-4\n",
    "client = OpenAI(api_key=\"YOUR_OPENAI_API_KEY\")  # Replace with your key\n",
    "\n",
    "# Cluster/category mapping\n",
    "cluster_mapping = {\n",
    "    0: \"Online offers\",\n",
    "    1: \"Electronics\",\n",
    "    2: \"For Kids\",\n",
    "    3: \"E-Readers & Home\",\n",
    "    4: \"Best Purchase\",\n",
    "    5: \"Voice-Enabled Tab\"\n",
    "}\n",
    "label_to_id = {v: k for k, v in cluster_mapping.items()}\n",
    "\n",
    "# --- CLASSIFICATION ---\n",
    "def classify_text(text):\n",
    "    result = classifier(text)\n",
    "    label = result[0]['label']\n",
    "    return {\"LABEL_0\": \"Negative\", \"LABEL_1\": \"Neutral\", \"LABEL_2\": \"Positive\"}.get(label, \"Unknown\")\n",
    "\n",
    "# --- STRUCTURED SUMMARIZATION ---\n",
    "def convert_df_to_json(df, selected_category):\n",
    "    grouped_data = defaultdict(lambda: {\"reviews\": [], \"category\": \"\"})\n",
    "    for _, row in df.iterrows():\n",
    "        if str(row.get('category')) != selected_category:\n",
    "            continue\n",
    "        product = row.get('name')\n",
    "        review_text = row.get('reviews.text')\n",
    "        rating = row.get('reviews.rating')\n",
    "        if pd.notnull(review_text) and pd.notnull(rating):\n",
    "            grouped_data[product][\"reviews\"].append({\n",
    "                \"text\": str(review_text),\n",
    "                \"rating\": float(rating)\n",
    "            })\n",
    "            grouped_data[product][\"category\"] = selected_category\n",
    "\n",
    "    structured_reviews = []\n",
    "    for product, details in grouped_data.items():\n",
    "        if len(details[\"reviews\"]) >= 2:\n",
    "            ratings = [r[\"rating\"] for r in details[\"reviews\"]]\n",
    "            texts = [r[\"text\"] for r in details[\"reviews\"]]\n",
    "            structured_reviews.append({\n",
    "                \"product_name\": product,\n",
    "                \"category\": details[\"category\"],\n",
    "                \"avg_rating\": sum(ratings) / len(ratings),\n",
    "                \"top_pros\": [t for t in texts if \"good\" in t.lower() or \"great\" in t.lower()][:2],\n",
    "                \"top_complaints\": [t for t in texts if \"bad\" in t.lower() or \"disappoint\" in t.lower()][:2]\n",
    "            })\n",
    "    return structured_reviews\n",
    "\n",
    "def build_insight_string(products):\n",
    "    sorted_products = sorted(products, key=lambda x: x[\"avg_rating\"], reverse=True)\n",
    "    top_3 = sorted_products[:3]\n",
    "    worst = sorted_products[-1]\n",
    "\n",
    "    insights_str = \"\"\n",
    "    for idx, p in enumerate(top_3, 1):\n",
    "        insights_str += f\"\"\"{idx}. {p['product_name']} - Rating: {p['avg_rating']:.2f}\n",
    "Key Pros: {\", \".join(p['top_pros']) or \"N/A\"}\n",
    "Top Complaints: {\", \".join(p['top_complaints']) or \"N/A\"}\\n\\n\"\"\"\n",
    "\n",
    "    insights_str += f\"Worst Product:\\n{worst['product_name']} - Rating: {worst['avg_rating']:.2f}\\n\"\n",
    "    insights_str += f\"Complaints: {', '.join(worst['top_complaints']) or 'N/A'}\"\n",
    "    return insights_str\n",
    "\n",
    "def generate_article(category, insights):\n",
    "    prompt = f\"\"\"\n",
    "You are a professional tech writer.\n",
    "\n",
    "Write a clear, structured summary about the product category: \"{category}\".\n",
    "\n",
    "The summary should include:\n",
    "1. Top 3 products in this category and their key differences.\n",
    "2. Top complaints for each of those top 3 products.\n",
    "3. The worst product and why users should avoid it.\n",
    "\n",
    "Make it professional, insightful, and easy to read — no bullet points or lists.\n",
    "\n",
    "Here are the insights to use:\n",
    "{insights}\n",
    "\n",
    "Now write the article.\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=900\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# --- GRADIO UI ---\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🤖 **الحاكم**\")\n",
    "\n",
    "    with gr.Tab(\"🔍 Classification\"):\n",
    "        txt_input = gr.Textbox(label=\"Enter text to classify\")\n",
    "        txt_output = gr.Label()\n",
    "        classify_btn = gr.Button(\"Classify\")\n",
    "        classify_btn.click(classify_text, txt_input, txt_output)\n",
    "\n",
    "    with gr.Tab(\"📚 Cluster & Summary\"):\n",
    "        gr.Markdown(\"### Step 1: Choose a Category\")\n",
    "        selected_category = gr.Textbox(label=\"Selected Category\", interactive=False)\n",
    "        with gr.Row():\n",
    "            for cluster_name in cluster_mapping.values():\n",
    "                gr.Button(cluster_name).click(lambda c=cluster_name: gr.Textbox.update(value=c), outputs=selected_category)\n",
    "\n",
    "        gr.Markdown(\"### Step 2: Upload Your Clustered CSV\")\n",
    "        file_input = gr.File(label=\"Upload CSV with `name`, `category`, `reviews.text`, `reviews.rating` columns\", file_types=[\".csv\"])\n",
    "        summary_output = gr.Textbox(label=\"Generated Summary\", lines=25)\n",
    "        generate_btn = gr.Button(\"Generate Summary\")\n",
    "\n",
    "        def handle_summary(file, category):\n",
    "            if not file:\n",
    "                return \"Please upload a file.\"\n",
    "            if not category:\n",
    "                return \"Please select a category first.\"\n",
    "            try:\n",
    "                df = pd.read_csv(file.name)\n",
    "                insights = convert_df_to_json(df, category)\n",
    "                if not insights:\n",
    "                    return f\"No sufficient reviews for the selected category: {category}\"\n",
    "                insight_str = build_insight_string(insights)\n",
    "                return generate_article(category, insight_str)\n",
    "            except Exception as e:\n",
    "                return f\"Error: {e}\"\n",
    "\n",
    "        generate_btn.click(handle_summary, inputs=[file_input, selected_category], outputs=summary_output)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "205c65e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Huawei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Huawei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#the one \n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize OpenAI client with your actual API key\n",
    "client = OpenAI(api_key=\"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\")\n",
    "# Load your main clustered review file from your provided path\n",
    "#df = pd.read_parquet(r\"C:\\Users\\Huawei\\Desktop\\cr\")\n",
    "df = pd.read_csv(r\"C:\\Users\\Huawei\\Desktop\\cr\\clustered_reviews.csv\")\n",
    "\n",
    "\n",
    "# Ensure required columns exist\n",
    "if 'reviews.text' not in df.columns or 'merged_cluster' not in df.columns:\n",
    "    raise ValueError(\"The CSV must contain 'reviews.text' and 'merged_cluster' columns.\")\n",
    "\n",
    "# Get unique cluster names\n",
    "cluster_labels = sorted(df[\"merged_cluster\"].dropna().unique().tolist())\n",
    "\n",
    "# --- GPT-Based Summary Function ---\n",
    "\n",
    "def generate_summary_from_cluster(cluster_label, file):\n",
    "    try:\n",
    "        # Load from file if uploaded, else use default df\n",
    "        if file is not None:\n",
    "            if file.name.endswith(\".csv\"):\n",
    "                user_df = pd.read_csv(file)\n",
    "            elif file.name.endswith(\".parquet\"):\n",
    "                user_df = pd.read_parquet(file)\n",
    "            else:\n",
    "                return \"❌ Unsupported file type. Please upload a CSV or Parquet file.\"\n",
    "\n",
    "            # Check required columns\n",
    "            if 'reviews.text' not in user_df.columns or 'merged_cluster' not in user_df.columns:\n",
    "                return \"❌ Uploaded file must contain 'reviews.text' and 'merged_cluster' columns.\"\n",
    "        else:\n",
    "            user_df = df\n",
    "\n",
    "        # Filter reviews by selected cluster\n",
    "        reviews = user_df[user_df[\"merged_cluster\"] == cluster_label][\"reviews.text\"].dropna().tolist()\n",
    "\n",
    "        if len(reviews) == 0:\n",
    "            return \"⚠️ No reviews found for the selected cluster.\"\n",
    "\n",
    "        if len(reviews) > 100:\n",
    "            reviews = reviews[:100]\n",
    "\n",
    "        # Format prompt for GPT-4\n",
    "        prompt = f\"\"\"\n",
    "You are a product review analyst.\n",
    "\n",
    "Here are customer reviews for a product category: \"{cluster_label}\".\n",
    "\n",
    "---\n",
    "\n",
    "{reviews}\n",
    "\n",
    "---\n",
    "\n",
    "Please generate a structured article-style summary with:\n",
    "\n",
    "1. Top 3 products in this category and their key differences.\n",
    "2. Top complaints for each of those top 3 products.\n",
    "3. The worst product and why users should avoid it.\n",
    "\n",
    "Make it insightful and clear.\n",
    "\"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful product review summarizer.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"❌ An error occurred while processing: {e}\"\n",
    "\n",
    "# --- Gradio UI ---\n",
    "\n",
    "with gr.Blocks(title=\"GPT-4 Review Summarizer by Cluster\") as demo:\n",
    "    gr.Markdown(\"## 🧠 GPT-4 Cluster-Based Review Summarizer\")\n",
    "    gr.Markdown(\"Upload review data (CSV/Parquet), pick a review cluster, and get a GPT-4 generated summary.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        category_dropdown = gr.Dropdown(\n",
    "            choices=cluster_labels,\n",
    "            label=\"Select a Cluster Label\"\n",
    "        )\n",
    "        file_upload = gr.File(label=\"(Optional) Upload your clustered review file\", file_types=[\".csv\", \".parquet\"])\n",
    "        summarize_btn = gr.Button(\"Summarize\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855713cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
